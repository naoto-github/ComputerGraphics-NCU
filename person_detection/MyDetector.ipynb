{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347b8753-5ca8-4adf-8d4d-10d7989756bd",
   "metadata": {},
   "source": [
    "# 人物検出のサンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6bd61a3-deab-43a2-85a7-1c5ec8f10e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331ac68-fa59-47f5-81a7-07a0c751d4da",
   "metadata": {},
   "source": [
    "## 対象画像とマスク画像のフォルダ（**要修正**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad4777cd-5528-4550-886b-e0b50ca8d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象画像のフォルダ（適宜修正すること）\n",
    "TARGET_FOLDER = \"./samples/origin/sample_10/images/\"\n",
    "\n",
    "# マスク画像を保存するフォルダ（適宜修正すること）\n",
    "MASK_FOLDER = \"./results/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a4734-4846-4edd-8acc-3e436aa07431",
   "metadata": {},
   "source": [
    "## マスク画像を生成する関数（**要修正**）\n",
    "### 【改良したアルゴリズムの説明をここに記載すること】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a064744-5db7-4593-8b16-c49aa5a261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像から人物のマスクを生成する関数（適宜修正すること）\n",
    "def detect(image):\n",
    "    \n",
    "    # グレースケールに変換\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 閾値127で2値化\n",
    "    _, image_binary = cv2.threshold(image_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # モルフォロジー処理\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    image_mask = cv2.morphologyEx(image_binary, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "    image_mask = cv2.morphologyEx(image_binary, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "    return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37711730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像から人物のマスクを生成する関数（HOG特徴量）\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "def detect_hog(image):\n",
    "    \n",
    "    # RGBに変換\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 人物検出\n",
    "    (rects, weights) = hog.detectMultiScale(image_rgb, winStride=(8, 8), padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # 画像と同じサイズのnumpy配列を作成\n",
    "    height, width, channels = image_rgb.shape\n",
    "    image_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "   # 5. 検出された矩形を描画\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(image_mask, (x, y), (x + w, y + h), 255, -1)\n",
    "    \n",
    "    return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec8b1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像から人物のマスクを生成する関数（YOLO）\n",
    "\n",
    "# YOLOの設定ファイルと重みファイルを読み込む\n",
    "config_path = \"yolo/yolov4-p6.cfg\"\n",
    "weights_path = \"yolo/yolov4-p6.weights\"\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# ラベル（クラス）の読み込み\n",
    "labels = open(\"yolo/coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# 出力レイヤーを取得\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "def detect_yolo(image):\n",
    "    # RGBに変換\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 画像サイズ\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # 画像の前処理\n",
    "    blob = cv2.dnn.blobFromImage(image_rgb, scalefactor=1/255.0, size=(640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # 人物検出\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    # 画像と同じサイズのグレースケールマスクを作成\n",
    "    image_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # 検出結果を解析\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # 各クラスのスコアを取得\n",
    "            class_id = np.argmax(scores)  # 最も高いスコアを持つクラスID\n",
    "            confidence = scores[class_id]  # そのクラスの信頼度\n",
    "\n",
    "            if class_id == 0 and confidence > 0.5:  # 人物クラスかつ信頼度が0.5以上\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (center_x, center_y, box_width, box_height) = box.astype(\"int\")\n",
    "\n",
    "                # バウンディングボックスの左上座標を計算\n",
    "                x = int(center_x - box_width / 2)\n",
    "                y = int(center_y - box_height / 2)\n",
    "\n",
    "                # マスクに矩形を描画\n",
    "                cv2.rectangle(image_mask, (x, y), (x + box_width, y + box_height), 255, -1)\n",
    "\n",
    "    return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b92c758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像から人物のマスクを生成する関数（YOLO+GRABCUT）\n",
    "# https://github.com/AlexeyAB/darknet?tab=readme-ov-file#pre-trained-models\n",
    "\n",
    "# YOLOの設定ファイルと重みファイルを読み込む\n",
    "config_path = \"yolo/yolov4-p6.cfg\"\n",
    "weights_path = \"yolo/yolov4-p6.weights\"\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# ラベル（クラス）の読み込み\n",
    "labels = open(\"yolo/coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# 出力レイヤーを取得\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "def detect_grabcut(image):\n",
    "\n",
    "    # RGBに変換\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 画像サイズ\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # 画像の前処理\n",
    "    blob = cv2.dnn.blobFromImage(image_rgb, scalefactor=1/255.0, size=(640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # 人物検出\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    # 画像と同じサイズのグレースケールマスクを作成\n",
    "    image_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # GrabCut用の背景・前景モデルを初期化\n",
    "    bgd_model = np.zeros((1, 65), np.float64)\n",
    "    fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    # 検出結果を解析\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # 各クラスのスコアを取得\n",
    "            class_id = np.argmax(scores)  # 最も高いスコアを持つクラスID\n",
    "            confidence = scores[class_id]  # そのクラスの信頼度\n",
    "\n",
    "            if class_id == 0 and confidence > 0.5:  # 人物クラスかつ信頼度が0.5以上\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (center_x, center_y, box_width, box_height) = box.astype(\"int\")\n",
    "\n",
    "                # バウンディングボックスの左上座標を計算\n",
    "                x = max(0, int(center_x - box_width / 2))\n",
    "                y = max(0, int(center_y - box_height / 2))\n",
    "                w = min(width - x, int(box_width))\n",
    "                h = min(height - y, int(box_height))\n",
    "\n",
    "                # GrabCut用の矩形を定義\n",
    "                rect = (x, y, w, h)\n",
    "\n",
    "                # GrabCutを適用（矩形内を前景候補とする）\n",
    "                cv2.grabCut(image, image_mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "                # マスクを2値化（0と2は背景，1と3は前景）\n",
    "                image_mask = np.where((image_mask == 2) | (image_mask == 0), 0, 255).astype('uint8')\n",
    "\n",
    "    return image_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3589469-3b78-4785-9c1c-13fd45c2dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像から人物のマスクを生成する関数（YOLO+GRABCUT+RESIZE）\n",
    "# https://github.com/AlexeyAB/darknet?tab=readme-ov-file#pre-trained-models\n",
    "\n",
    "# YOLOの設定ファイルと重みファイルを読み込む\n",
    "config_path = \"yolo/yolov4-p6.cfg\"\n",
    "weights_path = \"yolo/yolov4-p6.weights\"\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# ラベル（クラス）の読み込み\n",
    "labels = open(\"yolo/coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# 出力レイヤーを取得\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "def detect_grabcut_resize(image, target_size=(320, 320)):\n",
    "\n",
    "    # 元の画像サイズを取得\n",
    "    orig_height, orig_width = image.shape[:2]\n",
    "\n",
    "    # 低解像度にリサイズ\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "\n",
    "    # 低解像度での画像サイズ\n",
    "    height, width = resized_image.shape[:2]\n",
    "\n",
    "    # RGBに変換\n",
    "    image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 画像の前処理\n",
    "    blob = cv2.dnn.blobFromImage(image_rgb, scalefactor=1/255.0, size=(640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # 人物検出\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    # 低解像度のグレースケールマスクを作成\n",
    "    image_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # GrabCut用の背景・前景モデルを初期化\n",
    "    bgd_model = np.zeros((1, 65), np.float64)\n",
    "    fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    # 検出結果を解析\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # 各クラスのスコアを取得\n",
    "            class_id = np.argmax(scores)  # 最も高いスコアを持つクラスID\n",
    "            confidence = scores[class_id]  # そのクラスの信頼度\n",
    "\n",
    "            if class_id == 0 and confidence > 0.5:  # 人物クラスかつ信頼度が0.5以上\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (center_x, center_y, box_width, box_height) = box.astype(\"int\")\n",
    "\n",
    "                # バウンディングボックスの左上座標を計算\n",
    "                x = max(0, int(center_x - box_width / 2))\n",
    "                y = max(0, int(center_y - box_height / 2))\n",
    "                w = min(width - x, int(box_width))\n",
    "                h = min(height - y, int(box_height))\n",
    "\n",
    "                # GrabCut用の矩形が小さすぎる場合はスキップ\n",
    "                if w <= 1 or h <= 1:\n",
    "                    continue  # 矩形が小さいとエラーになるためスキップ\n",
    "\n",
    "                # 矩形が画像範囲を超えないようにクリップ\n",
    "                if x < 0 or y < 0 or w <= 0 or h <= 0 or (x + w) >= width or (y + h) >= height:\n",
    "                    continue  # 範囲外の矩形はスキップ             \n",
    "                \n",
    "                # GrabCut用の矩形を定義\n",
    "                rect = (x, y, w, h)\n",
    "\n",
    "                # GrabCutを適用（矩形内を前景候補とする）\n",
    "                cv2.grabCut(resized_image, image_mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "                # マスクを2値化（0と2は背景，1と3は前景）\n",
    "                image_mask = np.where((image_mask == 2) | (image_mask == 0), 0, 255).astype('uint8')\n",
    "\n",
    "    # 元の解像度にマスクをリサイズ\n",
    "    final_mask = cv2.resize(image_mask, (orig_width, orig_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return final_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2c65f-c456-44e8-8b1b-72ddee965246",
   "metadata": {},
   "source": [
    "## 対象画像のマスク画像を生成（修正不可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df2ad229-e74c-4449-9c47-0d64eb4522a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスク画像のフォルダが存在する場合は削除\n",
    "if os.path.exists(MASK_FOLDER):\n",
    "    shutil.rmtree(MASK_FOLDER)\n",
    "\n",
    "# マスク画像の保存フォルダの作成\n",
    "os.makedirs(MASK_FOLDER)\n",
    "\n",
    "# 画像一覧の取得\n",
    "files = sorted(glob.glob(TARGET_FOLDER + \"*.png\"))\n",
    "for file in files:\n",
    "    image = cv2.imread(file) # 画像の読み込み\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGRからRGBに変換\n",
    "\n",
    "    #image_mask = detect(image_rgb) \n",
    "    #image_mask = detect_hog(image_rgb)\n",
    "    #image_mask = detect_yolo(image_rgb)\n",
    "    #image_mask = detect_grabcut(image_rgb) \n",
    "    image_mask = detect_grabcut_resize(image_rgb, target_size=(320, 320)) \n",
    "\n",
    "    filename = os.path.basename(file)\n",
    "    cv2.imwrite(f\"{MASK_FOLDER}{filename}\", image_mask) # マスク画像を保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f17747-aec5-48cb-aab9-462fef39b02f",
   "metadata": {},
   "source": [
    "# IoUの算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "859152b9-a92c-4a87-9177-e3746e690d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of IOU: 0.74423\n"
     ]
    }
   ],
   "source": [
    "# IoU(Intersection over Union)の算出\n",
    "def IOU(mask, detection):\n",
    "    \n",
    "    # IoUの計算\n",
    "    intersection = np.logical_and(mask, detection)\n",
    "    union = np.logical_or(mask, detection)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# IOUの算出\n",
    "iou_list = []\n",
    "\n",
    "size = 100\n",
    "for i in range(size):\n",
    "    filename = str(i).zfill(3) + \".png\"\n",
    "\n",
    "    mask = cv2.imread(f\"./masks/{filename}\")\n",
    "    mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    output = cv2.imread(f\"./results/{filename}\")\n",
    "    output_gray = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    iou = IOU(mask_gray, output_gray)\n",
    "    iou_list.append(iou)\n",
    "    \n",
    "print(f\"Average of IOU: {np.round(np.mean(iou_list), 5)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391c2c-3190-4541-9fb1-67ab64c968e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
